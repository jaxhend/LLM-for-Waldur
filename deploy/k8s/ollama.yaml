apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: llm-testing-waldur-com
spec:
  replicas: 0
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      containers:
        - name: ollama-model
          image: ghcr.io/jaxhend/llm-for-waldur/ollama:gemma3
          imagePullPolicy: Never
          readinessProbe:
            exec:
              command: ["true"]
            initialDelaySeconds: 0
            periodSeconds: 1
          livenessProbe:
            exec:
              command: ["true"]
            initialDelaySeconds: 0
            periodSeconds: 5

          resources:
            limits:
              nvidia.com/gpu: 1
          command: ["ollama", "serve"]

        - name: ollama-worker
          image: ghcr.io/jaxhend/llm-for-waldur/ollama_worker:latest
          imagePullPolicy: IfNotPresent
          readinessProbe:
            exec:
              command: ["true"]
            initialDelaySeconds: 0
            periodSeconds: 1
          livenessProbe:
            exec:
              command: ["true"]
            initialDelaySeconds: 0
            periodSeconds: 5
          env:
            - name: REDIS_HOST
              value: "redis"
            - name: REDIS_PORT
              value: "6379"
            - name: REDIS_QUEUE
              value: "ollama-queue"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: redis-password
            - name: NODE_ENV
              value: "production"

      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
